{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18acf885",
   "metadata": {},
   "source": [
    "# 1) Retrieving data \n",
    "\n",
    "## Retrieving data from NoFluffJobs\n",
    "\n",
    "The first part of the exercise consists in retrieving data from the NoFluffJobs homepage. Complete the exercise following the steps:\n",
    "\n",
    "- Write a function that takes two parameters (job name and page number), and returns the HTML code of that page,\n",
    "- Write a function that takes one parameter (website code) and returns the information saying whether there are more offers on the page (`True` or `False`),\n",
    "- Write a function that takes one parameter (job name), and then in a loop, starting from 1 page:\n",
    "    - Retrieves the code of the given page,\n",
    "    - Checks if there are still ads on the page,\n",
    "    - If there are, it saves the HTML code to disk and goes to the next page,\n",
    "    - If there are not, it terminates the operation,\n",
    "    \n",
    "Remember to use previously written functions in step 3.\n",
    "\n",
    "At this stage, we do not process the data yet, we retrieve it as it is available.\n",
    "\n",
    "Run the script for the following jobs:\n",
    "\n",
    "- data analyst,\n",
    "- data scientist,\n",
    "- data engineer.\n",
    "\n",
    "### NOTE:\n",
    "For the website to generate its entire content after opening it needs to be clicked. In other words the process of loading the website should look as follows:\n",
    "\n",
    "- open the job offers page,\n",
    "- click any object on the page (e.g. accept cookies).\n",
    "\n",
    "#### File names\n",
    "\n",
    "We will adopt the following file naming convention:\n",
    "\n",
    "```{job_name}_{page_number}.html```\n",
    "\n",
    "For example: `data analyst_1.html` is going to mean the list of data analyst job offers from page one. The files should be saved in the `/data/raw` directory.\n",
    "\n",
    "#### Hints\n",
    "- Remember to add a time interval between every page transition, e.g. 5 seconds,\n",
    "- As a url to be opened by the browser, you can use the following template:\n",
    "\n",
    "```https://nofluffjobs.com/pl/jobs?criteria={job_name}&page={page_number}```\n",
    "\n",
    "- to retrieve the HTML content of the page you can use: `browser.page_source`,\n",
    "- Because we do not how how many pages we are going to have for each job, you can use a `while` loop,\n",
    "- if you want to stop executing the loop you can use the `break` keyword.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b58567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741ba461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for creating url based on parameters\n",
    "def url_code(job_name, page_number):\n",
    "    job_name2 = job_name.replace(\" \", \"%20\")  #replace space with %20 for url\n",
    "    url = f'https://nofluffjobs.com/pl/jobs?criteria={job_name2}&page={page_number}'  #writing url address with parameters\n",
    "    return url\n",
    "\n",
    "#Function that takes two parameters (job name and page number), and returns the HTML code of that page\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    return soup  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f343eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes one parameter (website code) and returns the information\n",
    "#saying whether there are more offers on the page (True or False),\n",
    "\n",
    "def more_offers(website_code):\n",
    "    try: #check if there is a \"multiple offers\" option\n",
    "        more = website_code.find(\"div\", class_=\"tw-flex tw-flex-wrap tw-justify-center tw-my-8 tw-gap-4 ng-star-inserted\").text\n",
    "        return True\n",
    "    except AttributeError:   #if not, it fails and we get an attribute error\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f21a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)Function that takes one parameter (job name), and then in a loop, starting from 1 page -retrieves the code\n",
    "#of the given page, checks if there are still ads on the page, if there are, it saves the HTML code to disk\n",
    "#and goes to the next page, if there are not, it terminates the operation\n",
    "    \n",
    "\n",
    "def save_html_ads(job_name):\n",
    "    page_number = 1    #starting from page 1\n",
    "    url = url_code(job_name, page_number) #url address for the job_name and page 1\n",
    "    \n",
    "    soup = get_html(url)  #get html code of that page\n",
    "\n",
    "    #save that html code to 'raw' folder\n",
    "    filename = f'data/raw/{job_name}_{page_number}.html'\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(str(soup))\n",
    "    \n",
    "    #do we have more pages with ads?\n",
    "    if more_offers(soup):  \n",
    "   \n",
    "        while True:  #until we have more pages\n",
    "            time.sleep(5)  #wait 5 seconds before saving html code of next page\n",
    "            page_number += 1   #next page\n",
    "            url = url_code(job_name, page_number)\n",
    "            \n",
    "            #save that html code to 'raw' folder\n",
    "            soup = get_html(url)  \n",
    "            filename = f'data/raw/{job_name}_{page_number}.html'  \n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(str(soup))\n",
    "                    \n",
    "            if not more_offers(soup):  #while loop breaks if there are no more pages with ads\n",
    "                print(f\"No more pages with job offers for {job_name}.\")  \n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801bb942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages with job offers for data scientist.\n"
     ]
    }
   ],
   "source": [
    "#save html codes for data scientist, data analyst and data engineer\n",
    "save_html_ads(\"data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219ce6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages with job offers for data analyst.\n"
     ]
    }
   ],
   "source": [
    "save_html_ads(\"data analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bfcca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages with job offers for data engineer.\n"
     ]
    }
   ],
   "source": [
    "save_html_ads(\"data engineer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
